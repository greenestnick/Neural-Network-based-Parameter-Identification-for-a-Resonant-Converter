{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "from SimDataScraper import *\n",
    "import matplotlib.pyplot as plt\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Regression NN\n",
    "class FFNN(nn.Module):\n",
    "    def __init__(self, inputSize, hiddenSize, outputSize, layerSize, activation_function):\n",
    "        super().__init__()\n",
    "\n",
    "        # Defining the input, hidden, and output layers. Here the hidden layer depth is made variable\n",
    "        self.lin0 = nn.Linear(inputSize, hiddenSize)\n",
    "        self.layers = nn.ModuleList([nn.Linear(hiddenSize, hiddenSize) for i in range(layerSize - 2)]) #layer size includes input & output hence the avgus 2\n",
    "        self.lin5 = nn.Linear(hiddenSize, outputSize)\n",
    "        \n",
    "        match(activation_function):\n",
    "            case \"sigmoid\":\n",
    "                self.actFunct = nn.Sigmoid()\n",
    "            case \"tanh\":\n",
    "                self.actFunct = nn.Tanh()\n",
    "            case \"relu\":\n",
    "                self.actFunct = nn.ReLU()\n",
    "            case \"lrelu\":\n",
    "                self.actFunct = nn.LeakyReLU()\n",
    "\n",
    "    # The forward pass basically just runs each layer and activation function until the output is calculated\n",
    "    def forward(self, x):\n",
    "        out = self.lin0(x)\n",
    "        out = self.actFunct(out)\n",
    "        \n",
    "        for l in self.layers:\n",
    "            out = l(out)\n",
    "            out = self.actFunct(out)\n",
    "\n",
    "        out = self.lin5(out)\n",
    "        return out\n",
    "\n",
    "# Classification NN\n",
    "class NNCLASS(nn.Module):\n",
    "    def __init__(self, inputSize, hiddenSize, outputSize, layerSize):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lin0 = nn.Linear(inputSize, hiddenSize)\n",
    "        self.layers = nn.ModuleList([nn.Linear(hiddenSize, hiddenSize) for i in range(layerSize - 2)])\n",
    "        self.lin5 = nn.Linear(hiddenSize, outputSize)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid() # Sigmoid use for the output layer to clamp between 0 and 1\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.lin0(x)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        for l in self.layers:\n",
    "            out = l(out)\n",
    "            out = self.relu(out)\n",
    "\n",
    "        out = self.lin5(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Opening the dataset as the serialized file with the pickle lib\n",
    "\n",
    "with open(\".\\\\OverMax_WithPhase\", 'rb+') as datasetFile:\n",
    "    dataset = pickle.load(datasetFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HSV2RGB(H, S, V):\n",
    "    C = V * S\n",
    "    divH = (H / 60)\n",
    "    X = C * (1 - abs((divH % 2) - 1))\n",
    "    m = V - C\n",
    "    \n",
    "    RGBp = tuple()\n",
    "    match (int)(divH):\n",
    "        case 0:\n",
    "            RGBp = (C, X, 0)\n",
    "        case 1:\n",
    "            RGBp = (X, C, 0)\n",
    "        case 2:\n",
    "            RGBp = (0, C, X)\n",
    "        case 3:\n",
    "            RGBp = (0, X, C)\n",
    "        case 4:\n",
    "            RGBp = (X, 0, C)\n",
    "        case 5:\n",
    "            RGBp = (C, 0, X)\n",
    "\n",
    "    R = (int)((RGBp[0] + m )* 255)\n",
    "    G = (int)((RGBp[1] + m )* 255)\n",
    "    B = (int)((RGBp[2] + m )* 255)\n",
    "\n",
    "    return (R, G, B)\n",
    "        \n",
    "hist, bins, patches = plt.hist(dataset.SimDict[\"Tj_Final_B\"], 150)\n",
    "\n",
    "'''\n",
    "bigColor = (60, 0.90, 0.75)\n",
    "smallColor = (240, 0.90, 0.35)\n",
    "\n",
    "maxCount = max(hist)\n",
    "avgCount = avg(hist)\n",
    "for i in range(len(patches)):\n",
    "    normVal = (hist[i] - avgCount) / (maxCount - minCount)\n",
    "\n",
    "    colr = [0, 0, 0]\n",
    "    for j in range(3):\n",
    "        colorRange = (bigColor[j] - smallColor[j])\n",
    "        coloravg = avg(bigColor[j], smallColor[j])\n",
    "        if colorRange < 0:\n",
    "            coloravg = max(bigColor[j], smallColor[j])\n",
    "        colr[j] = (normVal * colorRange + coloravg)\n",
    "\n",
    "    colr = HSV2RGB(*colr)\n",
    "    patches[i].set_facecolor(\"#\" + ('{:02X}{:02X}{:02X}').format(*colr))\n",
    "    #patches[i].set_edgecolor(\"#FFFFFF\")\n",
    "    #patches[i].set_linewidth(0.25)           \n",
    "'''\n",
    "\n",
    "fontSize = 18\n",
    "plt.title(\"Bottom Junction Temperature Data\", fontsize=fontSize * 0.75)\n",
    "plt.yscale('log')\n",
    "#plt.ylim((0,1))\n",
    "plt.xlabel(\"Normalized Value\", fontsize=fontSize)\n",
    "plt.ylabel(\"Count\", fontsize=fontSize)\n",
    "plt.minorticks_on()\n",
    "plt.grid(which=\"major\")\n",
    "plt.grid(which=\"minor\", axis='y', linewidth = 0.3)\n",
    "plt.tick_params(labelsize=fontSize*0.75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# SETUP FOR TRAINING\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #If a gpu is available, use it \n",
    "torch.manual_seed(1234) # Seed the random number generator for consisten results when training \n",
    "\n",
    "'''Set Up Variables'''\n",
    "hiddenLayerSize = 60\n",
    "layerSize = 6\n",
    "learningRate = 0.01\n",
    "epochs = 6000\n",
    "batchSize = 2**12\n",
    "train_test_ratio = 0.70\n",
    "activationFunction = 'lrelu'\n",
    "checkpointsDir = \"CheckpointsPhaseSet\"\n",
    "\n",
    "\n",
    "# Set the inputs desired through the dataset.inputs member variable. Inputs are a list of names \n",
    "#dataset.inputs = [\"i_ser_rms\", \"i_ser_max\", \"i_out_rms\", \"i_out_max\", \"i_in_rms\", \"i_in_max\", \"v_out_rms\", \"v_out_max\", \"Vin\", \"F\"]\n",
    "dataset.inputs = [\"i_ser_rms\", \"i_ser_max\", \"i_out_rms\", \"i_out_max\", \"i_in_rms\", \"i_in_max\", \"v_out_rms\", \"v_out_max\", \"Vin\", \"F\", \"phase_diff_avg\"]\n",
    "outputString = \"Lp\"\n",
    "\n",
    "#dataset.inputs = [\"v_ds_max_b\", \"v_ds_b_slew_min\", \"v_ds_b_slew_rms\", \"v_ds_b_slew_avg\", \"v_ds_b_slew_max\", \"i_ser_max\", \"q_gate_max_b\"]\n",
    "#outputString = \"zvs_b_true\"\n",
    "\n",
    "#dataset.inputs = [\"v_ds_on_max_t\", \"v_ds_on_min_t\", \"v_ds_on_max_b\", \"v_ds_on_min_b\",\"i_d_max_t\", \"i_d_min_t\", \"i_out_max\", \"i_in_max\", \"v_out_max\", \"Vin\", \"F\"]\n",
    "#outputString = \"tank_p_avg_loss\"\n",
    "\n",
    "#dataset.inputs = [\"v_ds_on_max_t\", \"v_ds_on_min_t\", \"i_d_max_t\", \"i_d_min_t\", \"i_out_max\", \"i_in_max\", \"v_out_max\", \"Vin\", \"F\"]\n",
    "#outputString = \"Tj_Final_T\"\n",
    "\n",
    "#dataset.inputs = [\"v_ds_on_max_t\", \"v_ds_on_min_t\", \"i_d_max_t\", \"i_d_min_t\", \"i_d_avg_t\", \"F\"]\n",
    "#outputString = \"Rdson_T\"\n",
    "\n",
    "#dataset.inputs = [\"v_gs_b_slew_max\", \"v_gs_b_slew_min\", \"q_gate_max_b\", \"q_gate_rms_b\", \"v_gs_max_b\", \"v_rg_max_b\", \"v_rg_rms_b\", \"v_ds_on_min_b\"]\n",
    "#outputString = \"Cgs_B\"\n",
    "\n",
    "#dataset.inputs = [\"v_ds_t_slew_max\", \"v_ds_t_slew_avg\", \"v_ds_t_slew_rms\", \"v_ds_t_slew_min\", \"q_gate_max_t\", \"v_gs_max_t\", \"v_ds_on_max_t\", \"i_ser_rms\", \"F\"]\n",
    "#outputString = \"Cds_T\"\n",
    "\n",
    "dataset.outputs = [outputString] #Same as the inputs member variable but only one output for our use case. These can be extended to more outputs\n",
    "dataset.PrePackSims() # Make sure to prepack the data. Without this the data cannot be accessed \n",
    "inputLayerSize = len(dataset.inputs) #auto set input and output layer sizes\n",
    "outputLayerSize = len(dataset.outputs)\n",
    "\n",
    "trainSet, testSet = dataset.Split(train_test_ratio, generator = None) #Split data into test and train sets\n",
    "trainLoader = DataLoader(trainSet, batch_size=batchSize, shuffle=True) #Pytorch data loader is used for batching and shuffling. One or train and test\n",
    "testLoader = DataLoader(testSet, batch_size=batchSize, shuffle=True)\n",
    "\n",
    "# Initialize the model here\n",
    "model = FFNN(inputLayerSize, hiddenLayerSize, outputLayerSize, layerSize, activationFunction)\n",
    "#model = NNCLASS(inputLayerSize, hiddenLayerSize, outputLayerSize, layerSize)\n",
    "model.cuda() #Make sure to put the model on the device (hopefully a gpu) for speed\n",
    "\n",
    "# Initialize the loss function\n",
    "criterion = nn.MSELoss()\n",
    "#criterion = nn.BCELoss()\n",
    "\n",
    "# Initialize the optimizer and learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learningRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# If the training is interrupted, you can save the last checkpoint of your model manually here\n",
    "\n",
    "# The name of the file is automated to include the output parameter, activation function, network size, number of epochs, and a hash of the input vector to differentiate inputs\n",
    "PATH_CHECKPOINT = \".\\\\\"+checkpointsDir+\"__%s_%s_(%d, %d)_%d_%s\" % (outputString, activationFunction, hiddenLayerSize, layerSize, epoch,  hashlib.md5((\"+\".join(dataset.inputs)).encode('utf-8')).hexdigest())\n",
    "# Pytorch allows you to save snapshots of your model as they train and reload them later for use/testing. This means you don't have to retrain at all, or you can load a model and continue training for that epoch\n",
    "# This takes a standard dictonary with these parameters\n",
    "torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict' : model.state_dict(),\n",
    "    'optimizer_state_dict' : optimizer.state_dict(),\n",
    "    'loss' : loss,\n",
    "}, \n",
    "PATH_CHECKPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "losses = [] #comment this out if you want to continue training \n",
    "#epochs = 1000\n",
    "startingEpoch = 0000 #If you are training a snapshot, enter the last epoch here so the progress update is correct\n",
    "\n",
    "# Training Loop \n",
    "for epoch in range(startingEpoch, startingEpoch + epochs):\n",
    "    for i, (inputs, outputs) in enumerate(trainLoader): #Loop over batches\n",
    "\n",
    "        # Reset the gradients and put inputs/outputs on the gpu\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = outputs.to(device)\n",
    "\n",
    "        #Forward Pass\n",
    "        prediction = model(inputs)\n",
    "        loss = criterion(prediction, outputs)\n",
    "        losses.append(loss)\n",
    "\n",
    "        #Backward Pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Save snapshot every 250\n",
    "        if (epoch + 1) % 250 == 0 and epoch != startingEpoch:\n",
    "            PATH_CHECKPOINT = \".\\\\\"+checkpointsDir+\"\\\\%s_%s_(%d, %d)_%d_%s\" % (outputString, activationFunction, hiddenLayerSize, layerSize, epoch + 1,  hashlib.md5((\"+\".join(dataset.inputs)).encode('utf-8')).hexdigest() )\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict' : model.state_dict(),\n",
    "                'optimizer_state_dict' : optimizer.state_dict(),\n",
    "                'loss' : loss,\n",
    "            }, \n",
    "            PATH_CHECKPOINT)\n",
    "        \n",
    "    print(\"EPOCH(%d/%d)  Loss: %lf\" % (epoch+1, startingEpoch + epochs, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Graph the loss over epochs\n",
    "plt.plot(torch.Tensor(losses).cpu())\n",
    "plt.grid()\n",
    "plt.xlabel(\"Samples\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.ylim((0.00,0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Loading a snapshot is done like this\n",
    "print(\"Check inputs are correct with: %s\" % hashlib.md5((\"+\".join(dataset.inputs)).encode('utf-8')).hexdigest())\n",
    "checkpointLoad = torch.load(\".\\\\\"+checkpointsDir+\"\\\\Lp_lrelu_(30, 6)_4000_4775d7d5a91afd083d46af026fc93343\")\n",
    "\n",
    "model.load_state_dict(checkpointLoad['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpointLoad['optimizer_state_dict'])\n",
    "epoch = checkpointLoad['epoch']\n",
    "loss = checkpointLoad['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inference Benchmark to get time/sample\n",
    "import time\n",
    "\n",
    "start = time.time_ns()\n",
    "with torch.no_grad():\n",
    "    for j, (inputs, outputs) in enumerate(testLoader):\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = outputs.to(device)\n",
    "        \n",
    "        #Forward Pass\n",
    "        prediction = model(inputs)\n",
    "\n",
    "end = time.time_ns()\n",
    "delta = end - start\n",
    "print(\" Delta/Sample [us] %0.3f\" % ((delta/1e3)/len(testLoader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Generate dummy test sets to compare scores too\n",
    "outputList = torch.tensor(dataset.SimDict[outputString], requires_grad=False)\n",
    "numSamples = len(testLoader.dataset)\n",
    "outputVar = outputList.var()\n",
    "DummySet_ConstMid = outputList.mean()\n",
    "DummySet_Mode,_ = outputList.mode()\n",
    "del outputList\n",
    "\n",
    "predList = torch.empty((0,1))\n",
    "truthList = torch.empty((0,1))\n",
    "\n",
    "with torch.no_grad():\n",
    "    sqrErr = 0\n",
    "    absErr = 0\n",
    "    errVar = 0\n",
    "    dummyAbsErr = torch.tensor([0, 0], dtype=float).to(device)\n",
    "    dummySqrErr = torch.tensor([0, 0], dtype=float).to(device)\n",
    "\n",
    "    for j, (inputs, outputs) in enumerate(testLoader):\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = outputs.to(device)\n",
    "        \n",
    "        #Forward Pass\n",
    "        prediction = model(inputs)\n",
    "\n",
    "        # Calculate Stats\n",
    "        absErr += torch.dist(prediction, outputs, 1)\n",
    "        sqrErr += torch.dist(prediction, outputs, 2) ** 2\n",
    "\n",
    "        dummyAbsErr[0] += torch.dist(DummySet_ConstMid, outputs, 1)\n",
    "        dummyAbsErr[1] += torch.dist(DummySet_Mode, outputs, 1)\n",
    "        dummySqrErr[0] += torch.dist(DummySet_ConstMid, outputs, 2) ** 2\n",
    "        dummySqrErr[1] += torch.dist(DummySet_Mode, outputs, 2) ** 2\n",
    "\n",
    "        predList = torch.concat((predList, prediction.to('cpu')))\n",
    "        truthList = torch.concat((truthList, outputs.to('cpu')))\n",
    "\n",
    "    sqrErr /= numSamples\n",
    "    absErr /= numSamples\n",
    "    dummyAbsErr /= numSamples\n",
    "    dummySqrErr /= numSamples\n",
    "    \n",
    "    print(\"MSE: %f\" % sqrErr)\n",
    "    print(\"RMS: %f\" % np.sqrt(sqrErr.to('cpu')))\n",
    "    print(\"MAE: %f\" % absErr)    \n",
    "    import sklearn.metrics \n",
    "    print(\"R^2: %f\" % sklearn.metrics.r2_score(np.array(truthList), np.array(predList)))    \n",
    "\n",
    "    \n",
    "    # Compare to scenario where a hypothetical NN outputs only the mean and mode of the test set. Serves as a baseline metric\n",
    "    print(\"\\nDummy Set Stats:\")\n",
    "    print(\"MEAN MSE: %f  MODE MSE: %f\" % (dummySqrErr[0], dummySqrErr[1]))\n",
    "    #print(\"MEAN RMS: %f  MODE RMS: %f\" % (torch.sqrt(dummySqrErr[0]), torch.sqrt(dummySqrErr[1])))\n",
    "    print(\"MEAN MAE: %f  MODE MAE: %f\" % (dummyAbsErr[0], dummyAbsErr[1]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Plotting the prediction/test histogram\n",
    "\n",
    "plotName = \"Top On-State Resistance (1500 epochs)\"\n",
    "\n",
    "plt.hist(np.array(truthList), 31)\n",
    "plt.hist(np.array(predList), 31)\n",
    "plt.grid()\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend([\"Ground Truth\", \"Predictions\"])\n",
    "plt.title(plotName)\n",
    "# plt.xlim((0.7,1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(predList[np.array(truthList) == 0], 100)\n",
    "\n",
    "#plt.boxplot(predList[np.array(truthList) == 0], whis=[0,100])\n",
    "\n",
    "plt.plot([0,1], linestyle='dotted', color='white')\n",
    "plt.hist2d(np.array(truthList).flatten(), np.array(predList).flatten(), [50,32])\n",
    "\n",
    "#plt.violinplot(np.array(predList), showmedians=True)\n",
    "\n",
    "plt.xlabel(\"Value\", fontsize=15)\n",
    "plt.ylabel(\"Count\", fontsize=15)\n",
    "plt.title(plotName, fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Plotting the truth vs prediction scatter plot\n",
    "plt.scatter(np.array(truthList), np.array(predList), marker='.')\n",
    "plt.scatter(np.array(truthList), np.array(predList), marker='.', color='r', alpha=0.008)\n",
    "plt.grid()\n",
    "plt.xlabel(\"Ground Truth\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.title(plotName) # Title set in histogram\n",
    "\n",
    "plt.plot([0,1], linestyle='dashed', color='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box and whisker plot testing\n",
    "\n",
    "def GetBinData(lower, upper, trueData, data):\n",
    "    lowerMask = trueData >= lower\n",
    "    upperMask = trueData < upper\n",
    "    mask = np.logical_and(lowerMask, upperMask)\n",
    "    return data[mask]\n",
    "\n",
    "#dataList = np.array(predList).flatten()\n",
    "\n",
    "#dat = GetBinData(0.0, 0.3125, np.array(truthList).flatten(), dataList)\n",
    "#plt.boxplot(dat, whis=[0,100])\n",
    "\n",
    "\n",
    "#counts, bins = np.histogram(truthList, 32)\n",
    "\n",
    "\n",
    "dataTruthList = np.array(truthList).flatten()\n",
    "dataPredList = np.array(predList).flatten()\n",
    "bins = np.unique(dataTruthList)\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "fontSize = 18\n",
    "\n",
    "boxWidth = bins[1] - bins[0]\n",
    "\n",
    "for i in range(0, len(bins), 1):\n",
    "    #print(\"%f -- %f\" % (bins[i- 1], bins[i]))\n",
    "\n",
    "    #dat = GetBinData(bins[i - 1], bins[i], dataTruthList, dataPredList)\n",
    "\n",
    "    mask = (dataTruthList == bins[i])\n",
    "    dat = dataPredList[mask]\n",
    "    boxDict = ax.boxplot(dat, whis=[0,100], positions=[bins[i]], widths=[boxWidth])\n",
    "\n",
    "    color = (1,0,0)\n",
    "    boxDict['medians'][0].set_color(color) \n",
    "    for x in boxDict['whiskers']:\n",
    "        x.set_color(color)\n",
    "    \n",
    "\n",
    "ax.plot([0,1], linestyle='dashed', color='black', linewidth='1.5')\n",
    "\n",
    "tickList = [x/10.0 for x in range(0, 12, 2)]\n",
    "ax.set_xticks(tickList, [str(x) for x in tickList])\n",
    "ax.set_xlim((-0.1,1.1))\n",
    "ax.grid()\n",
    "\n",
    "ax.set_title(plotName, size=fontSize)\n",
    "ax.set_xlabel(\"Normalized Value\", size=fontSize)\n",
    "ax.set_ylabel(\"Count\", size=fontSize)\n",
    "ax.tick_params(labelsize=fontSize)\n",
    "#plt.scatter(np.array(truthList), np.array(predList), marker='.')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Between Plot\n",
    "\n",
    "def GetBinData(lower, upper, trueData, data):\n",
    "    lowerMask = trueData >= lower\n",
    "    upperMask = trueData < upper\n",
    "    mask = np.logical_and(lowerMask, upperMask)\n",
    "    return data[mask]\n",
    "\n",
    "\n",
    "dataTruthList = np.array(truthList).flatten()\n",
    "dataPredList = np.array(predList).flatten()\n",
    "bins = np.unique(dataTruthList)\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "fontSize = 20\n",
    "\n",
    "boxWidth = bins[1] - bins[0]\n",
    "\n",
    "maxList = []\n",
    "minList = []\n",
    "medList = []\n",
    "avgList = []\n",
    "medList = []\n",
    "firstQuartList = []\n",
    "thirdQuartList = []\n",
    "\n",
    "for i in range(0, len(bins), 1):\n",
    "    mask = (dataTruthList == bins[i])\n",
    "    dat = dataPredList[mask]\n",
    "    maxList.append(np.max(dat))\n",
    "    minList.append(np.min(dat))\n",
    "    avgList.append(np.average(dat))\n",
    "    medList.append(np.median(dat))\n",
    "    firstQuartList.append(np.quantile(dat, 0.25))\n",
    "    thirdQuartList.append(np.quantile(dat, 0.75))\n",
    "\n",
    "ax.plot([0,1], linestyle='solid', color='r', linewidth='5', zorder=1)\n",
    "\n",
    "ax.fill_between(bins, maxList, minList, alpha=0.5, linewidth=0, color='dimgray', zorder=0)\n",
    "ax.fill_between(bins, thirdQuartList, firstQuartList, alpha=1, linewidth=0, color='turquoise', zorder=2)\n",
    "#ax.plot(bins, avgList, linewidth='1.5')\n",
    "#ax.plot(bins, medList, linewidth='1.5')\n",
    "#ax.scatter(bins, avgList)\n",
    "ax.scatter(bins, medList, color='k', zorder=2)\n",
    "\n",
    "\n",
    "tickList = [x/10.0 for x in range(0, 12, 2)]\n",
    "ax.set_xticks(tickList, [str(x) for x in tickList])\n",
    "ax.set_xlim((-0.025,1.025))\n",
    "ax.grid(color='k', linewidth=0.5)\n",
    "\n",
    "ax.set_title(plotName, size=fontSize*0.75)\n",
    "ax.set_xlabel(\"Normalized Value\", size=fontSize)\n",
    "ax.set_ylabel(\"Count\", size=fontSize)\n",
    "ax.tick_params(labelsize=fontSize*0.75)\n",
    "plt.scatter(np.array(truthList), np.array(predList), marker='.', alpha=0.3,zorder=-1, color='tab:blue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used for testing the classification\n",
    "\n",
    "with torch.no_grad():\n",
    "    predList = torch.empty((0,1))\n",
    "    truthList = torch.empty((0,1))\n",
    "\n",
    "    for j, (inputs, outputs) in enumerate(testLoader):\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = outputs.to(device)\n",
    "        \n",
    "        #Forward Pass\n",
    "        prediction = model(inputs)\n",
    "\n",
    "        predList = torch.concat((predList, prediction.to('cpu')))\n",
    "        truthList = torch.concat((truthList, outputs.to('cpu')))\n",
    "\n",
    "TP = torch.bitwise_and((truthList == 1), (predList > 0.5)).count_nonzero()\n",
    "FP = torch.bitwise_and((truthList == 1), (predList < 0.5)).count_nonzero()\n",
    "TN = torch.bitwise_and((truthList != 1), (predList < 0.5)).count_nonzero()\n",
    "FN =  torch.bitwise_and((truthList != 1), (predList > 0.5)).count_nonzero()\n",
    "\n",
    "print(\"Acc: %0.4f\" % ((TP+TN)/len(truthList)))\n",
    "print(\"Precision: %0.4f\" % (TP / (TP + FP)))\n",
    "print(\"Recall: %0.4f\" % (TP / (TP + FN)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
