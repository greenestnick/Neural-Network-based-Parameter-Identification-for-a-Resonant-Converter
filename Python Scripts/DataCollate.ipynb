{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used to just get the size and failure rate of a dataset\n",
    "\n",
    "from SimDataScraper import _GatherSims\n",
    "DIR = \"..\\\\ThesisDataSims\\\\SimFiles\\\\Saves\\\\Interpolation\\\\\"\n",
    "SID_KEYS, FR = _GatherSims(DIR)\n",
    "print(\"Failure Rate: %0.2f%% for %d sims\" % (FR * 100.0, len(SID_KEYS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script removes thermal log files missing measurements. There may have been a bug with LTSpice on Windows 11, but some thermal simulations completed but didn't write the measurements\n",
    "# So this script was made to remove those bugged cases\n",
    "\n",
    "import os\n",
    "from SimDataScraper import _GatherSims\n",
    "\n",
    "DIR = \"..\\\\ThesisDataSims\\\\SimFiles\\\\Saves\\\\Interpolation\\\\\"\n",
    "SID_KEYS, _= _GatherSims(DIR)\n",
    "\n",
    "count = 1\n",
    "for SID in list(SID_KEYS):\n",
    "    \n",
    "    for i in range(2):\n",
    "        \n",
    "        titlePrefix = \"THERM_\" + (\"T\" if not i else \"B\")\n",
    "        LOG_FILE = DIR  + titlePrefix + \"_\" + SID + \".log\"\n",
    "        thermWriteSuccess = False\n",
    "\n",
    "        with open(LOG_FILE , 'r') as file:\n",
    "            line = file.readline()\n",
    "            while line != \"\":\n",
    "                if line.startswith(\"Measurement:\"):  # Look to see if the thermal log file has the measurement line\n",
    "                    thermWriteSuccess = True\n",
    "                    break\n",
    "\n",
    "                line = file.readline()\n",
    "\n",
    "        if not thermWriteSuccess:\n",
    "            print(LOG_FILE)\n",
    "            os.remove(LOG_FILE)\n",
    "\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually creating the database which will invoke other functions to gather the data.\n",
    "\n",
    "from SimDataScraper import *\n",
    "#Desktop\\ThesisDataSims\\SimFiles\\Saves\n",
    "dataset = SimulationDataset(\"..\\\\ThesisDataSims\\\\SimFiles\\\\Saves\\\\Interpolation\\\\\", \n",
    "                            None, \n",
    "                            None, \n",
    "                            transform=MinMaxScale())\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the slew rates and packing into a dictonary\n",
    "\n",
    "from SimDataScraper import _GatherSims\n",
    "from SimDataScraper import _GenerateSlewRate\n",
    "from SimDataScraper import EngNotationToFloat\n",
    "import pickle\n",
    "\n",
    "\n",
    "DIR = \"..\\\\ThesisDataSims\\\\SimFiles\\\\Saves\\\\Interpolation\\\\\"\n",
    "SID_KEYS,_ = _GatherSims(DIR)\n",
    "\n",
    "with open(\".\\\\InterpolationDumpFile\", 'rb+') as datasetFile:\n",
    "    dataset = pickle.load(datasetFile)\n",
    "\n",
    "\n",
    "# Each SID is based on a random circuit configuration, independent of the case temperature. The case temperature is swept through ten points meaning each SID is really ten simulation points.\n",
    "# The problem is that one one SID is stored for every ten of these points. This block below simple repeats a SID ten times for every case temperature point. \n",
    "# This is something that should be fixed in the SimDataScraper.py file\n",
    "SIDLIST = []\n",
    "for SID in dataset.rawDict[\"SID\"]:\n",
    "    SIDLIST.extend([SID] * 10)\n",
    "\n",
    "dataset.rawDict[\"SID\"] = SIDLIST\n",
    "dataset.SimDict[\"SID\"] = SIDLIST\n",
    "del SIDLIST\n",
    "\n",
    "datasetDict = {}\n",
    "for i, x in enumerate(dataset.rawDict[\"SID\"]):\n",
    "    datasetDict[x] = dataset.rawDict[\"F\"][i]\n",
    "del dataset\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "slewDict = {}\n",
    "slewDict[\"SID\"] = SID_KEYS\n",
    "\n",
    "count = 1\n",
    "finalCount = len(SID_KEYS)\n",
    "for SID in SID_KEYS:\n",
    "    print(\"(%d/%d):%s\" % (count, finalCount, SID))\n",
    "    freq = datasetDict[SID]\n",
    "    tempDict = {}\n",
    "\n",
    "    # Vd slew\n",
    "    tempDict |= _GenerateSlewRate(DIR, SID, freq, \"v(vd1,vp)\", \"v_ds_t\")\n",
    "    tempDict |= _GenerateSlewRate(DIR, SID, freq, \"v(vd2,vss)\", \"v_ds_b\")\n",
    "    # Id slew\n",
    "    tempDict |= _GenerateSlewRate(DIR, SID, freq, \"i(id_meas1)\", \"id_t\")\n",
    "    tempDict |= _GenerateSlewRate(DIR, SID, freq, \"i(id_meas2)\", \"id_b\")\n",
    "    # Vg Slew\n",
    "    tempDict |= _GenerateSlewRate(DIR, SID, freq, \"v(vg1,vp)\", \"v_gs_t\")\n",
    "    tempDict |= _GenerateSlewRate(DIR, SID, freq, \"v(vg2,vss)\", \"v_gs_b\")\n",
    "    # Ig slew\n",
    "    tempDict |= _GenerateSlewRate(DIR, SID, freq, \"i(Rg1)\", \"ig_t\")\n",
    "    tempDict |= _GenerateSlewRate(DIR, SID, freq, \"i(Rg2)\", \"ig_b\")\n",
    "\n",
    "    for key in tempDict:\n",
    "        slewDict.setdefault(key, []).append(tempDict[key])\n",
    "\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Vdson by masking out the time a switch is on based on the known frequency and some buffer to avoid ringing signals in the measurements\n",
    "\n",
    "from SimDataScraper import _GatherSims\n",
    "from SimDataScraper import _GenerateSlewRate\n",
    "from SimDataScraper import EngNotationToFloat\n",
    "import ltspice\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "def SearchFloat(data, value):\n",
    "    diff = np.array(data - ([value] * len(data)))\n",
    "    return np.argmin(np.absolute(diff))\n",
    "\n",
    "DIR = \"..\\\\ThesisDataSims\\\\SimFiles\\\\Saves\\\\Interpolation\"\n",
    "SID_KEYS,_ = _GatherSims(DIR)\n",
    "\n",
    "with open(\".\\\\InterpolationDumpFile\", 'rb+') as datasetFile:\n",
    "    dataset = pickle.load(datasetFile)\n",
    "\n",
    "\n",
    "# Each SID is based on a random circuit configuration, independent of the case temperature. The case temperature is swept through ten points meaning each SID is really ten simulation points.\n",
    "# The problem is that one one SID is stored for every ten of these points. This block below simple repeats a SID ten times for every case temperature point. \n",
    "# This is something that should be fixed in the SimDataScraper.py file\n",
    "SIDLIST = []\n",
    "for SID in dataset.rawDict[\"SID\"]:\n",
    "    SIDLIST.extend([SID] * 10)\n",
    "\n",
    "dataset.rawDict[\"SID\"] = SIDLIST\n",
    "dataset.SimDict[\"SID\"] = SIDLIST\n",
    "del SIDLIST\n",
    "\n",
    "datasetDict = {}\n",
    "for i, x in enumerate(dataset.rawDict[\"SID\"]):\n",
    "    datasetDict[x] = dataset.rawDict[\"F\"][i]\n",
    "del dataset\n",
    "    \n",
    "\n",
    "vdsonDict = {}\n",
    "vdsonDict[\"SID\"] = SID_KEYS\n",
    "\n",
    "count = 1\n",
    "finalCount = len(SID_KEYS)\n",
    "for SID in SID_KEYS:\n",
    "    print(\"(%d/%d):%s\" % (count, finalCount, SID))\n",
    "    freq = datasetDict[SID]\n",
    "\n",
    "    lts = ltspice.Ltspice(DIR +\"\\\\SIM_\" + SID + \".raw\")\n",
    "    lts.parse()\n",
    "    time = lts.get_time()\n",
    "    vds = lts.get_data(\"v(vd1,vp)\")\n",
    "\n",
    "    maxList = []\n",
    "    minList = []\n",
    "    midList = []\n",
    "    # For each measured cycle\n",
    "    for i in range(3):\n",
    "        cycStart = 1.55 + i\n",
    "        cycEnd = 1.95 + i\n",
    "        cycMid = 1.75 + i\n",
    "\n",
    "        start = SearchFloat(time, (cycStart/freq))\n",
    "        end = SearchFloat(time, (cycEnd/freq))\n",
    "        mid = SearchFloat(time, (cycMid/freq))\n",
    "\n",
    "        vdsondata = vds[start:end]\n",
    "        maxList.append(np.max(vdsondata))\n",
    "        minList.append(np.min(vdsondata))\n",
    "        midList.append(vds[mid])\n",
    "    \n",
    "    vdsonDict.setdefault(\"v_ds_on_max_t\", []).append(np.max(maxList))\n",
    "    vdsonDict.setdefault(\"v_ds_on_min_t\", []).append(np.min(minList))\n",
    "    vdsonDict.setdefault(\"v_ds_on_pp_t\", []).append(np.max(maxList) - np.min(minList))\n",
    "    vdsonDict.setdefault(\"v_ds_on_mid_t\", []).append(np.mean(midList))\n",
    "\n",
    "    vds = lts.get_data(\"v(vd2,vss)\")\n",
    "    maxList = []\n",
    "    minList = []\n",
    "    midList = []\n",
    "    for i in range(3):\n",
    "        cycStart = 1.55 - 0.5 + i\n",
    "        cycEnd = 1.95 - 0.5 + i\n",
    "        cycMid = 1.75 - 0.5 + i\n",
    "        start = SearchFloat(time, (cycStart/freq))\n",
    "        end = SearchFloat(time, (cycEnd/freq))\n",
    "        mid = SearchFloat(time, (cycMid/freq))\n",
    "\n",
    "        vdsondata = vds[start:end]\n",
    "        maxList.append(np.max(vdsondata))\n",
    "        minList.append(np.min(vdsondata))\n",
    "        midList.append(vds[mid])\n",
    "    \n",
    "    vdsonDict.setdefault(\"v_ds_on_max_b\", []).append(np.max(maxList))\n",
    "    vdsonDict.setdefault(\"v_ds_on_min_b\", []).append(np.min(minList))\n",
    "    vdsonDict.setdefault(\"v_ds_on_pp_b\", []).append(np.max(maxList) - np.min(minList))\n",
    "    vdsonDict.setdefault(\"v_ds_on_mid_b\", []).append(np.mean(midList))\n",
    "\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the pickle library to seralize (write to a file) the dataset to make it easy to transfer\n",
    "# Can be modified to save the Vdson and Slew rate structures\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "fileName = \".\\\\InterpolationDumpFile\"\n",
    "\n",
    "with open(fileName, 'wb+') as dataFile:\n",
    "    pickle.dump(dataset, dataFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks that the seralized file was successful by loading it and checking a few keys\n",
    "\n",
    "import pickle\n",
    "\n",
    "fileName = \".\\\\InterpolationDumpFile\"\n",
    "with open(fileName, 'rb+') as dataFile:\n",
    "    readDataset = pickle.load(dataFile)\n",
    "\n",
    "#print(len(readDataset.rawDict[\"SID\"]))\n",
    "#print(len(readDataset.rawDict[\"F\"]))\n",
    "#print(len(readDataset.rawDict[\"Tc\"]))\n",
    "#print(len(readDataset.rawDict[\"Tj_Final_T\"]))\n",
    "#print(len(readDataset.rawDict[\"Tj_Final_B\"]))\n",
    "\n",
    "for key in readDataset:\n",
    "    print(key, end=\": \")\n",
    "    print(readDataset[key][:10])\n",
    "\n",
    "del readDataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
